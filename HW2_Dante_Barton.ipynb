{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dantebarton/collabNotebook/blob/main/HW2_Dante_Barton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **`One step toward building our own models: How to prepare data in pytorch?`**"
      ],
      "metadata": {
        "id": "wLj0vB7F8hvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Started with PyTorch:\n",
        "\n",
        "In this assignment, we will get familiar with PyTorch, a leading library for deep learning. We'll learn how to prepare our data for training models, but first, let's understand what PyTorch is.\n",
        "\n",
        "What is PyTorch?\n",
        "PyTorch is a widely acclaimed open-source machine learning library for Python, famous for its flexibility, user-friendly interface, and dynamic computation graph. It's extensively utilized in deep learning and artificial intelligence applications, offering a rich ecosystem for researchers and developers to build cutting-edge AI models.\n",
        "\n",
        "Computations on Tensors:\n",
        "\n",
        "Tensors are the core component of PyTorch, serving as the building blocks for model architecture and data. They are similar to arrays and matrices, enabling efficient computation and manipulation of multi-dimensional data. Here's a brief introduction to performing basic tensor\n",
        "\n",
        "Operations in PyTorch:\n",
        "\n"
      ],
      "metadata": {
        "id": "eYYb5jRdZtqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create tensors\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5, 6])\n",
        "\n",
        "# Basic operations\n",
        "sum_xy = x + y\n",
        "product_xy = x * y\n",
        "\n",
        "print(\"Sum:\", sum_xy)\n",
        "print(\"Product:\", product_xy)\n"
      ],
      "metadata": {
        "id": "wG0fsP2QZ6ti",
        "outputId": "7f1655e5-5073-421c-d45e-ecdf4310302f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: tensor([5, 7, 9])\n",
            "Product: tensor([ 4, 10, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Tensor Basics"
      ],
      "metadata": {
        "id": "vTWfSjcpZuJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a 1D Tensor\n",
        "a = torch.tensor([2, 3, 4])\n",
        "print(\"Tensor a:\", a)\n",
        "\n",
        "# Create a 2D Tensor of zeros\n",
        "b = torch.zeros((2, 3))\n",
        "print(\"Tensor b:\", b)\n"
      ],
      "metadata": {
        "id": "fg94Q-YkalYL",
        "outputId": "7cc98c80-a5e9-4732-f639-cc1d6facd162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor a: tensor([2, 3, 4])\n",
            "Tensor b: tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Todo**:\n",
        "Create a 3D tensor filled with ones and print its shape, data type, and the device it is stored on.\n"
      ],
      "metadata": {
        "id": "ASHIjTGRakop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.ones((3, 3))\n",
        "print(\"Tensor c:\", c)\n",
        "print(\"Tensor c shape:\", c.shape)\n",
        "print(\"Tensor c data type:\", c.dtype)\n",
        "print(\"Tensor c device:\", c.device)"
      ],
      "metadata": {
        "id": "SZkf7bZfdvID",
        "outputId": "d0107b97-7acb-4cf6-d619-08cb2462f1ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor c: tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Tensor c shape: torch.Size([3, 3])\n",
            "Tensor c data type: torch.float32\n",
            "Tensor c device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Tensor Operations\n"
      ],
      "metadata": {
        "id": "PhPo2Hsha2BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2])\n",
        "y = torch.tensor([3, 4])\n",
        "\n",
        "# Addition\n",
        "z = x + y\n",
        "print(\"Addition:\", z)\n",
        "\n",
        "# Subtraction\n",
        "s = x - y\n",
        "print(\"Subtraction:\",  s)\n",
        "\n",
        "# Multiplication\n",
        "m = x * y\n",
        "print(\"Multiplication:\", m)\n",
        "\n",
        "# Division\n",
        "d = x / y\n",
        "print(\"Division:\", d)"
      ],
      "metadata": {
        "id": "5xcIKraoaziP",
        "outputId": "8aab5023-c3c2-42e9-99b8-65c944d00b7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Addition: tensor([4, 6])\n",
            "Subtraction: tensor([-2, -2])\n",
            "Multiplication: tensor([3, 8])\n",
            "Division: tensor([0.3333, 0.5000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Todo**: Perform subtraction, multiplication, and division on x and y."
      ],
      "metadata": {
        "id": "AVKF4xQLayzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Indexing, Slicing, and Joining\n"
      ],
      "metadata": {
        "id": "GaiuEOpNZuLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a 2D tensor\n",
        "t = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "# Slicing\n",
        "slice_t = t[:, 1]\n",
        "print(\"Sliced Tensor:\", slice_t)"
      ],
      "metadata": {
        "id": "V_Z-dfkMdzEb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f35d550-b37e-4180-962c-bf0a0c6a36b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sliced Tensor: tensor([2, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Todo**: Extract the first row from tensor t. Then, concatenate with itself vertically and horizontally, and print the results."
      ],
      "metadata": {
        "id": "opItEho6ZuNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a 2D tensor\n",
        "t = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "sliced_t = t[0]\n",
        "print(\"First row from t:\", sliced_t)\n",
        "\n",
        "vertical_cat = torch.cat((sliced_t.unsqueeze(0), sliced_t.unsqueeze(0)), dim=0)\n",
        "print(\"Vertical Concatenation:\", vertical_cat)\n",
        "\n",
        "horizontal_cat = torch.cat((sliced_t.unsqueeze(1), sliced_t.unsqueeze(1)), dim=1)\n",
        "print(\"Horizontal Concatenation:\", horizontal_cat)"
      ],
      "metadata": {
        "id": "aKp6mQDTd6NP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a785c7-7d75-4ac5-a74a-ea86b4db5ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row from t: tensor([1, 2])\n",
            "Vertical Concatenation: tensor([[1, 2],\n",
            "        [1, 2]])\n",
            "Horizontal Concatenation: tensor([[1, 1],\n",
            "        [2, 2]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: Reshaping Tensors\n"
      ],
      "metadata": {
        "id": "daPL-F50d-ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a tensor\n",
        "t = torch.arange(4)\n",
        "\n",
        "# Reshape to a 2x2 tensor\n",
        "reshaped_t = t.view(2, 2)\n",
        "print(\"Reshaped Tensor:\", reshaped_t)"
      ],
      "metadata": {
        "id": "O0FoyWI0eABD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c69c7dd-7c99-4227-fad3-1380d96f77ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped Tensor: tensor([[0, 1],\n",
            "        [2, 3]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Todo**: Use reshape to convert reshaped_t back into a 1D tensor. Then, experiment with unsqueeze and squeeze to add and remove dimensions from the tensor."
      ],
      "metadata": {
        "id": "W3jHXcvdd_Sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reshape_t = t.reshape(1, 4)\n",
        "print(\"Reshaped Tensor t:\", reshape_t)\n",
        "\n",
        "# Test of squeeze\n",
        "t = t.squeeze(0)\n",
        "print(t)\n",
        "\n",
        "# Test of unsqueeze\n",
        "t = t.unsqueeze(-1)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "cHg_uJi2d6m6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180930c6-6830-4a2f-9681-f2c9b42a781a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped Tensor t: tensor([[0, 1, 2, 3]])\n",
            "tensor([[0],\n",
            "        [1],\n",
            "        [2],\n",
            "        [3]])\n",
            "tensor([[[0]],\n",
            "\n",
            "        [[1]],\n",
            "\n",
            "        [[2]],\n",
            "\n",
            "        [[3]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: Loading CSV data"
      ],
      "metadata": {
        "id": "lnJWcHiWeKTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sample demonstrates how to read a CSV file into a Pandas DataFrame and then convert specific columns into a PyTorch tensor. We specifically convert the features to a float tensor, which is common for input data in machine learning models."
      ],
      "metadata": {
        "id": "GRZ1Mr_qfWi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data.csv' is a CSV file in the same directory with columns 'feature1', 'feature2', 'label'\n",
        "csv_file = 'data.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Convert DataFrame to PyTorch Tensor\n",
        "# Here, we're only converting the features to a tensor. In practice, you might convert labels too.\n",
        "features = torch.tensor(df[['feature1', 'feature2']].values, dtype=torch.float)\n",
        "print(\"Features Tensor:\", features)"
      ],
      "metadata": {
        "id": "wwuqJ9ineHDn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "e8e52fb8-eaa1-4c2e-9369-8b0546170612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-162d1765e7b9>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assuming 'data.csv' is a CSV file in the same directory with columns 'feature1', 'feature2', 'label'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert DataFrame to PyTorch Tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from this link:\n",
        "https://www.stats.govt.nz/large-datasets/csv-files-for-download/\n",
        "\n",
        "\n",
        "load a CSV file that includes at least three features and a label column. Convert these into two tensors: one for the features (features_tensor) and one for the labels (labels_tensor). Assume the labels are integer values. After conversion, print the shape of both tensors."
      ],
      "metadata": {
        "id": "UPVKpGnYfjBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_file = '/content/water-physical-stock-account-quarterly-1995-2020-CSV.csv'\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "features_tensor = torch.tensor(df[['RID', 'value', 'year']].values, dtype=torch.int)\n",
        "labels_tensor = torch.tensor(df[['Quarter']].values, dtype=torch.int)\n",
        "print(\"Features Tensor:\", features_tensor.shape)\n",
        "print(\"Labels Tensor:\", labels_tensor.shape)"
      ],
      "metadata": {
        "id": "J7dEOS7QfnMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c7abb0-e939-4941-b31c-666be7c58e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features Tensor: torch.Size([17008, 3])\n",
            "Labels Tensor: torch.Size([17008, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6: Manipulating CSV Data with PyTorch Tensors\n"
      ],
      "metadata": {
        "id": "_wA6KOnDf5_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo: Extract the first 10 rows from features_tensor and the corresponding labels from labels_tensor.\n"
      ],
      "metadata": {
        "id": "Ml_d9tI7hm1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract first 10 rows from features_tensor\n",
        "first_10_features = features_tensor[:10]\n",
        "print(\"The first 10 rows:\", first_10_features)\n",
        "\n",
        "# Extract first 10 rows from labels_tensor\n",
        "first_10_labels = labels_tensor[:10]\n",
        "print(\"The first 10 labels:\", first_10_labels)"
      ],
      "metadata": {
        "id": "yzB9SZzdhkM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64d497a3-264c-47e5-dcda-2e45eb2dfcf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 10 rows: tensor([[    1,     0,  1995],\n",
            "        [    1,     0,  1995],\n",
            "        [    1,     0,  1995],\n",
            "        [    1,     0,  1995],\n",
            "        [    2,     0,  1995],\n",
            "        [    2,     0,  1995],\n",
            "        [    2,     0,  1995],\n",
            "        [    2,     0,  1995],\n",
            "        [    3, 19446,  1995],\n",
            "        [    3, 18933,  1995]], dtype=torch.int32)\n",
            "The first 10 labels: tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4],\n",
            "        [1],\n",
            "        [2]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo: Create a combined tensor by stacking the extracted features and labels along a new dimension. Discuss potential use cases for such operations in data preprocessing."
      ],
      "metadata": {
        "id": "E9l2cxssh0zY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A potential use case for this operation can assist in data preparation for neural networks by simplifying the data feeding process."
      ],
      "metadata": {
        "id": "QIUv0fGAlvVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates combined tensor\n",
        "combined_features_and_labels = torch.cat((features_tensor, labels_tensor), dim=1)\n",
        "print(\"Combined Tensors:\", combined_features_and_labels)"
      ],
      "metadata": {
        "id": "IyS0X5XXh1lH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf9fd4b-a3ee-4ca3-f8c6-113957988f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Tensors: tensor([[     1,      0,   1995,      1],\n",
            "        [     1,      0,   1995,      2],\n",
            "        [     1,      0,   1995,      3],\n",
            "        ...,\n",
            "        [    19, -26601,   2019,      2],\n",
            "        [    19, -28203,   2019,      3],\n",
            "        [    19, -30802,   2019,      4]], dtype=torch.int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 7: Loading MNIST dataset"
      ],
      "metadata": {
        "id": "_sz1MB6Eh2z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load MINST data set with the code below:"
      ],
      "metadata": {
        "id": "kERHPyMkmQIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Get one batch of training images and labels\n",
        "images, labels = next(iter(trainloader))\n",
        "print(\"Shape of images:\", images.shape)\n",
        "print(\"Shape of labels:\", labels.shape)"
      ],
      "metadata": {
        "id": "g1nXy7SWi37O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19aee115-7286-48a2-9802-e07c88ad8d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 351609479.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 23987266.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 101035666.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4864792.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Shape of images: torch.Size([64, 1, 28, 28])\n",
            "Shape of labels: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo: Print the shape of the images and labels tensors."
      ],
      "metadata": {
        "id": "y41qEWW9m4ZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the images and labels tensors\n",
        "print(\"Shape of images:\", images.shape)\n",
        "print(\"Shape of labels:\", labels.shape)"
      ],
      "metadata": {
        "id": "gX-KlnFYmy0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17943d52-ac1f-4a8b-b016-c37462424054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images: torch.Size([64, 1, 28, 28])\n",
            "Shape of labels: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo: Extract and visualize the first 5 images from the batch."
      ],
      "metadata": {
        "id": "YD7ghXidnJX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "\n",
        "first_5_images = images[:5]\n",
        "\n",
        "image_grid = torchvision.utils.make_grid(first_5_images, nrow=5)\n",
        "\n",
        "# Convert the grid of images to numpy array for visualization\n",
        "image_grid_np = image_grid.numpy()\n",
        "\n",
        "# Plot the images\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(image_grid_np.transpose((1, 2, 0)), cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UHfifeNynVN9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "6fe39167-d4c9-4855-e830-88a322560e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo: Reshape the batch of images into a shape of (-1, 28*28) to make them ready for a fully connected layer input."
      ],
      "metadata": {
        "id": "DcmDteEUnWOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshapes the batch of images\n",
        "reshaped_images = images.view(-1, 28*28)\n",
        "\n",
        "print(\"Reshaped images:\", reshaped_images.shape)"
      ],
      "metadata": {
        "id": "MmznG9dFnfW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb61767-9c31-41e8-9441-3b85bb64e2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reshaped images: torch.Size([64, 784])\n"
          ]
        }
      ]
    }
  ]
}